# 20240112_TIL - 메모리와 캐시 메모리

## RAM의 특징과 종류

주기억장치에는 RAM과 ROM이 있고, 우리가 흔히 이야기 하는 `메모리`는 RAM을 주로 의미한다고 했다. 이번 시간에는 RAM에 대해서 깊게 이야기 해보자.

### RAM의 특징

RAM에는 실행 중인 프로그램(프로세스)의 명령어와 데이터가 보관된다. 이 데이터들은 전원이 꺼지면 사라지고, 이 때문에 RAM을 `휘발성 저장장치`라고 한다. 반면에 HDD, SSD 등의 보조기억장치는 전원이 꺼져도 내용이 사라지지 않아 `비휘발성 저장장치`라고 한다.

### RAM의 용량과 성능

CPU는 보조기억장치에 있는 내용에 직접 접근할 수 없다. 그렇기 때문에 필요한 정보가 보조기억장치에 있는 경우, 이를 RAM으로 복사해서 저장하고 사용한다.

그런데 RAM의 용량이 작다고 해보자. 이러면 그만큼 프로세스의 정보 중 보조기억장치에 남아 있는 부분이 많아지게 되고, 그만큼 RAM에서 보조기억장치를 자주 방문해야 하므로 그만큼 성능에서 손해를 보게 된다. 이건 마치 만화카페에서 한 작품을 정주행하려고 할 때, 북카트의 크기가 작아서 책장을 자주 다녀 오는 횟수가 많아 완독에 걸리는 시간이 늘어 나는 것과 같다.

그러므로 RAM의 용량이 크면 그만큼 프로세스의 정보를 RAM이 많이 포함할 수 있고, 프로그램을 실행하는 데 걸리는 시간을 줄여준다. 이는 특히 여러 프로그램을 동시에 실행할 때 유리하다. 

그럼 RAM 용량과 속도는 무조건 비례할까? 그건 아니다. 극단적인 예시지만 20권짜리 시리즈물을 읽으려고 하는데 100칸짜리 카트를 쓰는 것이나 1000칸짜리 카트를 쓰는 것이나 동일한 결과를 가져오는 것처럼 말이다.

### RAM의 종류

크게 `DRAM`, `SRAM`, `SDRAM`, `DDR SDRAM`으로 나뉜다.

`DRAM`은 `Dynamic RAM`의 줄임말로, 동적으로 메모리 용량을 조절한다. 즉 시간이 지나면 자연스럽게 이전 데이터가 사라지게 된다. 단점으로는 일정 주기로 데이터를 다시 저장해야 한다는 점이지만, 저렴하고 소비전력이 낮으며, 크기는 작으면서 대용량의 RAM 설계가 용이하기 때문에 우리가 흔히 `메모리`라고 하는 데서 많이 사용된다.

`SRAM`은 반대로 `Static RAM`을 의미한다. 저장된 데이터가 변하지 않는다는 뜻이다. 주기적으로 불러올 필요가 없으므로 DRAM에 비해 상대적으로 속도가 빠르다. 그러나 정확히 반대의 이유로 대중적으로 사용되지는 않으며, 대신 `캐시 메모리`처럼 대용량으로 만들어질 필요는 없지만 속도가 빨라야 할 때 주로 사용된다.

`SDRAM`은 클럭 신호와 동기화된(`Synchronized`) DRAM을 말한다. DRAM의 발전된 형태로 클럭 신호와 동기화 되어 있으므로 CPU와 정보를 서로 주고 받을 수 있다.

`DDR SDRAM`은 `SDRAM`에서 데이터를 주고 받는 대역폭이 더 넓어진 버전으로, 현재 가장 상용화 되어 있다. DDR은 `Double Data Rate`를 말하는데 이는 기존 SDRAM에 비해 대역폭이 두 배 넓어, 한 클럭 신호에 CPU와 두 번 소통할 수 있다는 것을 말한다. 그래서 기존의 `SDRAM`을 `S(Single)DR SDRAM`이라고도 한다.

우리가 RAM을 고르다 보면 DDR3, DDR4 등 뒤에 숫자가 붙는 것을 볼 수 있다. DDRn은 DDR(n-1) SDRAM에 비해 대역폭이 두 배 넓어졌다는 것을 의미한다. 즉 DDR4는 SDR SDRAM 보다 대역폭이 2^4배 넓은 16배를 자랑한다. 한 클럭 신호에 32번 소통이 가능한 것이다.

## 메모리의 주소 공간

### 물리 주소와 논리 주소

주소 공간에는 `물리 주소`와 `논리 주소`가 있다. `물리 주소`는 실제 메모리 하드웨어에서 데이터나 명령어가 저장된 위치를 말하고, `논리 주소`는 CPU와 프로세스가 사용하는 주소다. 

예를 들어서 내가 어떤 물품을 배달할 때 사용하는 실제 주소지는 `서울특별시 xx구 yy동 zz빌딩 a0b호`겠지만, 이를 집 앞에서 배달해주시는 택배 아저씨가 집이 정확히 어디냐고 물어 보시면  `a층 올라와서 b번째 방`이라고 이야기할 것이다. 

그럼 택배 아저씨는 `a층 올라와서 b번째 방`이라는 정보만 가지고 정확하게 물품을 배달할 수 있을까? 아니다. `a0b호`라는 실제 주소는 모든 빌딩이 갖고 있을 수 있는 정보다. 그렇기 때문에 실제 주소지를 기반으로 한 정보가 필요하다.

컴퓨터로 돌아와보자. CPU와 메모리는 프로세스 실행을 위해 명령어와 데이터를 긴밀하게 주고 받아야 한다. 그렇기 때문에 CPU와 메모리는 각자에게 주소를 정확하게 이야기 해줄 수 있어야 한다. 이를 위해 CPU와 주소 버스 사이에서 논리주소와 물리주소를 변환해주는 하드웨어가 있는데, 이를 `MMU(Memory Management Unit)`이라고 한다.

### MMU와 베이스 레지스터 기반 주소 지정 방식

MMU는 주소 변환을 위해 `베이스 레지스터 기반 주소 지정 방식`을 사용한다. 

`베이스 레지스터`는 프로그램의 첫 물리주소를 기억한다. MMU는 CPU에서 메모리에 신호를 보낼 때, CPU가 발생시키는 논리 주소에 베이스 레지스터가 가지고 있는 첫 주소값을 더해서 물리 주소로 변환하여 주소를 메모리로 보낸다. 즉, 논리 주소는 곧 `프로그램의 첫 물리 주소로부터 상대적인 거리`를 나타내는 것과 같다.

예를 들어 현재 프로세스가 `A`라고 할 때, CPU는 프로세스 내 상대적인 주소만 알고 있으므로 `A의 100번지 주소에 있는 데이터를 지워라`라고 말할 것이다. 이 때 베이스 레지스터는 프로그램 `A`의 첫 주소로 `300`을 알고 있다고 하자. 그러면 MMU는 위 신호를 `400번지에 있는 데이터를 지워라`라는, 물리 주소를 통한 정보를 전달할 것이다.

### 메모리 보호 기법

위와 같은 방식을 사용할 때 주의해야 할 점이 있다. 마치 프로그래밍에서 index 범위를 잘못 지정해 넘어갈 때와 비슷한 일인데, 실제 물리 주소가 1001~2000인 프로그램 A에게 `A의 1500번지 데이터를 삭제해라`라는 명령을 내리게 되는 경우 원치 않는 결과가 발생할 수 있다. 위와 같은 경우 실제로는 주소 범위를 벗어난 2501번지를 가리키는 것이기 때문이다. 

이런 오류를 피하기 위해 `한계 레지스터`가 등장한다. 한계 레지스터는 프로세스가 가질 수 있는 논리주소의 범위를 저장한다. 즉 프로그램의 물리 주소 범위는 `[베이스 레지스터값, 베이스 레지스터값 + 한계 레지스터 값)`이 된다.

위의 예시를 가져와보면, 이 상황에서 베이스 레지스터에는 1001이, 한계 레지스터에는 1000이 저장되어 있을 것이다. 이 때 `A의 1500번지`라는 말은 곧 `2501번지`라는 계산이 나오게 되고, 이는 허용 가능한 최대 범위인 `2000번지`를 넘어서는 값이므로 인터럽트(트랩)를 발생시키고 해당 명령어는 실행되지 않는다.

## 캐시 메모리

CPU는 명령어를 실행하기 위해 메모리와 쉴새없이 소통한다. 그러나 CPU의 연산 속도가 CPU 외부를 갔다 와야 하는 시간에 비해 월등히 빠르기 때문에 어쩔 수 없이 CPU가 일을 하지 못하는 시간이 생겨난다. 이를 조금이라도 줄이기 위해 `캐시 메모리`가 등장한다.

### 저장 장치 계층 구조

우리가 지금까지 배운 것들 중에서 저장과 관련된 하드웨어들을 정리해보자.

`레지스터`는 CPU 내부에 있는 작은 저장 장치다. 연산을 담당하는 ALU와 가장 가까이 있기 때문에 처리 속도가 가장 빠르다. 그렇지만 용량을 기대할 수는 없고, 작은 만큼 성능을 올리려면 많은 비용이 든다.

`메모리`는 레지스터보다는 용량을 많이 담을 수 있지만, 어쩔 수 없이 CPU 외부에 있는 하드웨어이므로 속도에서 레지스터보다 손해를 본다.

`보조기억장치`는 위 2개에 비할 수 없는 압도적인 용량을 보여준다. 그러나 CPU가 직접 접근할 수 없으므로 메모리에 복사하고 불러오는, 상대적으로 오랜 시간을 필요로 한다.

즉 이 세 가지 저장 장치들은 각각이 서로에 대한 trade-off를 가지고 있다. 이를 CPU에 가까움을 기준으로 피라미드식으로 나타낸 것을 `저장 장치 계층 구조`라고 한다. 위로 갈 수록 속도는 빠르고 용량은 작으며 비싸다.

### 캐시 메모리의 특징

`캐시 메모리`는 CPU와 메모리 사이에 위치한 SRAM 기반의 저장 장치다. 위에서 공부한 내용대로 속도에서는 `메모리`보다 우월하지만 용량은 상대적으로 작다. 그러나 레지스터보다는 큰 용량을 가지고 있다. 

이러한 캐시 메모리는 한 곳에만 위치하는 것이 아닌데, CPU에 가까운 순서대로 L1, L2, L3 캐시라는 이름을 가진다. CPU는 캐시된 데이터를 찾을 때 가장 가까운 L1부터 데이터를 찾아 나간다. 일반적으로 `L1, L2 캐시`는 코어 내에, `L3 캐시`는 코어와 메모리 사이에 위치한다. 이 캐시 메모리들도 저장 장치 계층 구조를 따르므로 내부적으로 속도는 `L1`이 가장 빠르고, 용량은 `L3`가 가장 크다.

한편 L1 캐시의 경우 속도를 더욱 빠르게 하기 위해 명령어와 데이터를 각각 L1I와 L1D 캐시로 나누어 담는 방식을 채택하기도 하는데, 이를 `분리형 캐시`라고 한다. 

### 참조 지역성 원리

그럼 캐시 메모리를 알차게 사용하려면, 어떤 데이터를 어디에 캐싱해야 할까? 

사실 캐시 메모리의 입장에서 다음에 필요한 데이터가 무엇인지 정확하게 알고 미리 저장해 두는 것은 불가능하다. 그렇기 때문에 호출될 데이터를 최대한 합리적으로 예측해서 그 주소를 저장한다. 이를 위해서는 `참조 지역성 원리`를 이해해야 한다.

> CPU는 최근에 접근했던 메모리 공간과 그 근처를 접근하려는 경향이 있다.
> 

1) 프로그래밍 언어에서 한 변수를 선언하면 해당 변수 데이터가 저장된 주소는 계속해서 참조될 것이다. 그렇기 때문에 캐시 메모리는 한 번 참조된 주소는 다음에 또 참조될 수 있을 것이라고 예측하고 해당 주소를 들고 있는다. 이렇게 최근에 접근했던 메모리 공간을 다시 접근하려는 경향을 `시간 지역성`이라고 한다.

2) 프로그램은 보통 관련된 데이터들끼리 한 데 모여있다. 그리고 프로그램 내 세부 기능들도 그 기능들끼리 같은 지역에 모여있다. 한 번 워드를 실행하고 나면 거기서 사용할 워드 프로세서 프로그램 내 메소드는 그 근처에 존재할 것이다. 이를 `공간 지역성`이라고 한다. 이 때문에 캐시 메모리는 어느 정도 다음에 참조할 주소를 예측할 수 있다. 

캐시 데이터는 이런 참조 지역성 원리에 입각해 CPU가 사용할 법한 데이터를 예측한다. 이 때 필요한 데이터를 정확하게 들고 있으면 `캐시 히트`라고 한다. 반대는 `캐시 미스`가 있다. 그리고 적중하는 비율을 `캐시 적중률`이라고 해서 `캐시 히트 횟수 / 히트 + 미스 횟수`로 나타낸다. 참고로 우리가 사용하는 컴퓨터의 캐시 적중률은 대략 85~95%를 상회한다고 한다.